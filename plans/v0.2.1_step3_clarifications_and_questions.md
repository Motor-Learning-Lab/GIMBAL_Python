# v0.2.1 Step 3: Clarifications and Questions

**Created:** December 17, 2025
**Status:** For User Review

This document outlines questions, uncertainties, and proposed changes that require user input before completing Step 3 implementation.

---

## Section 1: Changes Already Made to step3 Document

### 1.1 Fixed Duplicate Status Line
- **Issue:** Document had "**Status:** Draft for Copilot implementation" listed twice at the top
- **Action:** Removed duplicate (will be fixed in document update)

### 1.2 Corrected Title Mismatch
- **Issue:** Title says "v0.2.1 Step‑1 Plan" but document is about Step 3 (synthetic data)
- **Action:** Will change title to "v0.2.1 Step 3 Plan: Synthetic Data Generation"

### 1.3 Updated Scope Description
- **Issue:** Scope mentions 6 topics (cleanup, alignment, synthetic data, fitting, runner, camera priors) but document only covers synthetic data
- **Proposed Action:** Remove items 1-2 and 6 from scope, or split into separate documents
- **Recommendation:** This should be Step 3 ONLY (synthetic data), with other steps in separate documents

---

## Section 2: Current Codebase vs Plan Requirements

### 2.1 Existing Motion Generator (Simple vs Second-Order Attractor)

**Current state in `gimbal/synthetic_data.py`:**
- Uses simple directional noise model: canonical direction + Gaussian noise in 3D space
- Normalized per-joint after adding noise
- State-dependent but NOT continuous dynamics (no velocity, no damping)
- Root is random walk (simple Brownian motion)

**Plan requirement (Section 3.3):**
- Second-order attractor system with position `q_t`, velocity `v_t`, acceleration `a_t`
- State-dependent parameters: `(mu_k, omega_k, zeta_k, sigma_process_k)`
- Explicit damping ratio `zeta` and natural frequency `omega`
- Requires tuning `sigma_process_k` to achieve target `sigma_pose_k`

**Questions:**
1. **Priority:** Should we REPLACE the existing simple generator or ADD the second-order generator as an option?
   - Option A: Replace entirely (breaking change, cleaner API)
   - Option B: Add new function `generate_skeletal_motion_continuous()` alongside existing
   - Recommendation: **Option A** - the plan is explicit that continuous motion is required

2. **Backward compatibility:** Existing demos/tests use current generator. Should we:
   - Update all existing code to use new generator?
   - Keep old generator under legacy name for reference?
   - Recommendation: Update all code, keep old version as `generate_skeletal_motion_legacy()` temporarily

3. **Initialization:** Plan says initialize at `mu_{z0}` with `v_0 = 0`. Current code initializes root at `[0,0,100]`. Should we:
   - Still use explicit root position for initialization?
   - Make initialization configurable in JSON?
   - Recommendation: Make root initialization part of config `motion.root_params.init_pos`

### 2.2 Configuration Format (Current vs JSON)

**Current state:**
- Uses Python `NamedTuple` (`SyntheticDataConfig`) 
- In-memory only, not serializable to disk
- Limited parameters (T, C, S, kappa, obs_noise_std, occlusion_rate, root_noise_std, random_seed)

**Plan requirement:**
- JSON configuration files
- Much richer schema with nested structure (skeleton, states, motion, cameras, observation)
- Must be serializable into .npz metadata

**Questions:**
1. **Migration path:** Should we keep `SyntheticDataConfig` as a Python wrapper around JSON config?
   - Pro: Backward compatibility, type hints, autocompletion
   - Con: Two representations to maintain
   - Recommendation: Keep `SyntheticDataConfig` but deprecate direct use, load from JSON

2. **Config validation:** Who validates config correctness (schema compliance)?
   - Option A: Python code with explicit checks
   - Option B: JSON Schema validation (requires jsonschema package)
   - Option C: Pydantic models (requires pydantic package)
   - Recommendation: **Option A** for now (avoid new dependencies), can upgrade later

### 2.3 Camera Model (Current Implementation)

**Current state in `gimbal/synthetic_data.py`:**
- `generate_camera_matrices()` uses `camera_utils.build_projection_matrix()`
- Fixed positions: front (+X), side (+Y), overhead (+Z)
- Fixed focal length (10.0)
- Properly implements look-at with up-vector
- Returns 3x4 projection matrices P = K[R|t]

**Plan requirement (Section 3.4):**
- Cameras defined in config with explicit K, R, t, image_size
- Guidance on FOV → focal length conversion
- Helper functions for camera placement recommended

**Questions:**
1. **Config vs generator:** Should camera generation be:
   - Option A: Always explicit in config (user specifies K, R, t directly)
   - Option B: Config can specify either explicit params OR placement parameters (position, target, FOV)
   - Recommendation: **Option B** - more user-friendly, with helper to convert placement → K/R/t

2. **Image size:** Current code doesn't track image size. Plan requires it for:
   - Bounds checking (coordinates within frame)
   - FOV → focal length calculations
   - Recommendation: Add to config, default to 1280x720 for backward compatibility

### 2.4 Camera Quality / Identifiability Check (New Requirement)

**Current state:** No identifiability checking

**Plan requirement (Section 3.4):**
- Compute pairwise ray angles for each (t, j) point
- Require `min_cameras_per_point` with minimum `min_pairwise_ray_angle_deg`
- Must hold for `min_fraction_points` of observations

**Questions:**
1. **When to check:** Should this be:
   - Option A: Run after generation, fail if check fails
   - Option B: Run during camera placement, iteratively adjust cameras
   - Option C: Run as separate validation function, report but don't fail
   - Recommendation: **Option A** for now (fail fast), can add auto-adjustment later

2. **Performance:** For large datasets (T=1000, K=20, C=5), this is ~100K point checks
   - Should we subsample for speed?
   - Recommendation: Check every frame but add `--skip-quality-check` flag for speed

### 2.5 Dataset Artifact Format (Section 3.5)

**Current state:** `SyntheticMotionData` is NamedTuple, not saved to disk

**Plan requirement:**
- Save to .npz file
- Include: x_true, u_true, z_true, A_true, y_2d, skeleton metadata, camera params, config text + hash

**Questions:**
1. **What is `A_true`?** Plan mentions it but doesn't define in context
   - Is this the acceleration array from the second-order system?
   - Or is it something else (attention? alignment?)?
   - **NEEDS CLARIFICATION**

2. **Config hash:** Should we use:
   - Option A: Hash of JSON string (sensitive to formatting)
   - Option B: Hash of sorted canonical JSON (stable)
   - Option C: SHA256 of file contents
   - Recommendation: **Option B** - stable and deterministic

3. **Metadata storage:** Should we store config as:
   - npz['config_json'] = config_str (as string)
   - npz['config'] = json.loads(config_str) (as dict, but npz might not preserve structure)
   - Recommendation: Store as string, parse on load

### 2.6 Canonical Datasets L00-L03 (Section 3.6)

**Current state:** No canonical datasets exist

**Plan requirement:**
- L00: minimal (1 state, low noise, no outliers, no missingness)
- L01: L00 + increased noise
- L02: L00 + outliers
- L03: L00 + missingness

**Questions:**
1. **Skeleton for L00-L03:** Plan says "keep skeleton fixed and minimal"
   - Should we use existing `DEMO_V0_1_SKELETON`?
   - Or create new minimal skeleton?
   - Current demo skeleton: 7 joints, simple tree structure
   - Recommendation: Use `DEMO_V0_1_SKELETON` for consistency with existing tests

2. **Specific parameters:** Plan gives guidance but not exact values
   - L01 noise: How much to increase? (current default is 5.0 px)
   - L02 outliers: What fraction? What magnitude?
   - L03 missingness: What Bernoulli p?
   - Recommendation: Start conservative then tune based on metrics:
     - L00: noise_px=2.0 (tight)
     - L01: noise_px=10.0 (moderate)
     - L02: noise_px=2.0, outliers=10% at 50px SD
     - L03: noise_px=2.0, missingness=20%

3. **Sequence length T:** Plan doesn't specify
   - Current default is T=60
   - For testing, shorter is faster but less interesting
   - Recommendation: T=100 for L00-L03 (1-2 second sequences at 60 fps)

### 2.7 Metrics and Thresholds (Section 3.8)

**Plan requirement:**
- Bone length consistency (max/mean deviation)
- Direction normalization health
- Smoothness metrics (speed, acceleration, jerk distributions)
- State sanity (dwell times, transition counts)
- 2D sanity (missingness fraction, outlier fraction, bounds violations)

**Questions:**
1. **Jerk thresholds:** Plan says "calibrate using L00 then hold constant"
   - Should calibration be manual or automated?
   - Recommendation: Run L00 once, record 95th percentile values, hardcode as thresholds with 2× safety margin

2. **Relative vs absolute:** Plan prefers relative thresholds
   - How to make jerk threshold relative to skeleton scale?
   - Recommendation: Normalize by `bone_length_mean * fps^3` (jerk has units of length/time³)

3. **Test failures:** If L00-L03 fail thresholds:
   - Option A: Test fails immediately (strict)
   - Option B: Test warns but passes (informational)
   - Option C: Test fails but prints diagnostic suggestions
   - Recommendation: **Option C** - fail but give actionable feedback

---

## Section 3: Missing Specifications

### 3.1 Figure Specifications (Section 3.7)

**Plan lists 5 figure types but lacks details:**

1. **3D skeleton motion preview:** 
   - Which joints? (plan says "root + 2-4 extremities")
   - How to identify "extremities" programmatically?
   - Recommendation: Root + all leaf nodes (joints with no children)

2. **3D pose snapshots:**
   - How many frames in grid? (plan says "small grid")
   - Which frames? (evenly spaced? state transitions? first/last?)
   - Recommendation: 3×3 grid, evenly spaced through sequence

3. **2D reprojection montage:**
   - Which camera? (plan says "one camera")
   - How many frames? (plan says "a few frames")
   - Recommendation: Camera 0, same 9 frames as 3D grid

4. **Missingness/outlier summary:**
   - What format? Bar chart? Heatmap? Table?
   - Recommendation: Two heatmaps (cameras × joints) for missingness and outliers

5. **State timeline:**
   - How to visualize transition matrix? Heatmap with probabilities?
   - Recommendation: (1) Line plot of states over time, (2) Heatmap of transition matrix with values

### 3.2 Dataset Report Format (Section 3.9)

**Plan mentions `dataset_report.md` but doesn't specify content**

**Proposed content:**
```markdown
# Dataset: {config_name}

## Configuration
- Timesteps: {T}
- States: {S}
- Cameras: {C}
- Joints: {K}
- Noise: {noise_px} px
- Outliers: {outlier_fraction}
- Missingness: {missingness_fraction}

## Generation Summary
- Seed: {seed}
- Generated: {timestamp}
- Config hash: {hash}

## Quality Metrics
[Paste metrics.json content formatted]

## Figures
- See figures/ directory for visualizations
```

**Question:** Is this sufficient or should we add more analysis?

### 3.3 Directory Structure

**Plan doesn't specify where datasets should be saved**

**Proposed structure:**
```
tests/pipeline/
├── configs/
│   └── v0.2.1/
│       ├── _template.json (with comments)
│       ├── L00_minimal.json
│       ├── L01_noise.json
│       ├── L02_outliers.json
│       └── L03_missingness.json
├── datasets/
│   └── v0.2.1/
│       ├── L00_minimal/
│       │   ├── dataset.npz
│       │   ├── metrics.json
│       │   ├── dataset_report.md
│       │   └── figures/
│       │       ├── motion_3d.png
│       │       ├── poses_3d.png
│       │       ├── reprojection_2d.png
│       │       ├── missingness.png
│       │       └── states.png
│       ├── L01_noise/...
│       ├── L02_outliers/...
│       └── L03_missingness/...
└── test_v0_2_1_synth_generator.py
```

**Questions:**
1. Should datasets be in `tests/pipeline/datasets/` or `results/pipeline/v0.2.1/`?
   - Recommendation: `tests/pipeline/datasets/` since they're reference data for testing

2. Should figures be in subdirectory or alongside dataset.npz?
   - Recommendation: Subdirectory keeps things organized

---

## Section 4: Implementation Dependencies

### 4.1 New Python Package Requirements

**For full implementation we may need:**
- `matplotlib` or `plotly` - for figure generation (already in pixi.toml?)
- `scipy` - for finite differences (jerk calculation)
- `json` - built-in
- `hashlib` - built-in
- `pathlib` - built-in

**Action:** Verify matplotlib in pixi.toml, add if missing

### 4.2 Testing Infrastructure

**Need to create:**
- `tests/pipeline/` directory structure
- Runner script (e.g., `generate_dataset.py`)
- Integration test file
- Metrics computation module
- Visualization module

**Question:** Should metrics/visualization be in `gimbal/` (library code) or `tests/pipeline/utils/` (test utilities)?
- Recommendation: Start in `tests/pipeline/utils/`, move to library if reused elsewhere

---

## Section 5: Recommendations for User Decision

### Priority 1 (Must Decide Before Implementation):

1. **Motion generator replacement:** Replace simple generator with second-order attractor? (Recommend: YES, with legacy backup)

2. **`A_true` definition:** What is this array in the dataset? (NEEDS CLARIFICATION)

3. **Config approach:** JSON-only or Python wrapper? (Recommend: JSON primary, Python wrapper for convenience)

### Priority 2 (Can Use Recommendations):

4. **L00-L03 parameters:** Use recommended values above or specify different? (Can tune after first run)

5. **Figure details:** Use recommendations in Section 3.1? (Can refine after seeing output)

6. **Directory structure:** Use proposed structure in Section 3.3? (Seems reasonable)

### Priority 3 (Implementation Details):

7. **Camera placement helpers:** Implement placement → K/R/t conversion? (Useful but not critical for MVP)

8. **Identifiability check:** Fail-fast vs warn vs auto-adjust? (Start with fail-fast)

9. **Metrics calibration:** Manual threshold setting vs automated? (Start manual)

---

## Section 6: Proposed Implementation Order

1. **Phase 1: Core Data Generation**
   - Update `synthetic_data.py` with second-order attractor
   - Implement JSON config loading
   - Add camera quality checking
   - Test with simple manual config

2. **Phase 2: Canonical Configs**
   - Create directory structure
   - Write L00-L03 JSON configs
   - Generate datasets (no visualization yet)
   - Verify .npz format

3. **Phase 3: Metrics & Validation**
   - Implement metrics.json computation
   - Run on L00, establish baseline thresholds
   - Write pytest integration test
   - Verify tests pass

4. **Phase 4: Visualization**
   - Implement 5 figure types
   - Generate figures for L00-L03
   - Create dataset_report.md generator
   - Manual visual inspection

5. **Phase 5: Runner & Polish**
   - Create unified runner script
   - Add CLI arguments for config selection
   - Document usage in README
   - Final end-to-end test

---

## Section 7: Timeline Estimate

**With user decisions resolved:**
- Phase 1: 3-4 hours (core functionality)
- Phase 2: 1-2 hours (config files, simple generation)
- Phase 3: 2-3 hours (metrics computation, testing)
- Phase 4: 2-3 hours (visualization, requires iteration)
- Phase 5: 1 hour (integration, documentation)

**Total: ~9-13 hours of focused implementation**

(Assumes user decisions come back quickly, no major design changes needed)

---

## Next Steps

**User should review this document and provide:**
1. Answer to `A_true` question (Priority 1)
2. Confirmation or modification of motion generator replacement approach
3. Confirmation of L00-L03 parameter recommendations
4. Any corrections to proposed directory structure
5. Green light to proceed with Phases 1-5

**Agent will then:**
1. Update v0.2.1_step3_synthetic_data_generation.md with clarifications
2. Begin Phase 1 implementation
3. Iterate through phases with periodic checkpoints
4. Request user visual inspection after Phase 4 completes
